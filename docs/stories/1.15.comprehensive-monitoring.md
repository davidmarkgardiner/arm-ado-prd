# Story 1.15: Comprehensive Monitoring Setup

<!-- Powered by BMADâ„¢ Core -->

## Status
Draft

## Story
**As a** Platform Engineer,
**I want** to setup comprehensive monitoring for the management cluster,
**So that** I can proactively identify and resolve issues.

## Acceptance Criteria
1. Prometheus installed and configured
2. Grafana dashboards created
3. AlertManager configured with notification channels
4. Azure Monitor integration configured
5. Custom metrics for ASO and Flux implemented

## Tasks / Subtasks
- [ ] Install Prometheus using operator or Helm (AC: 1)
  - [ ] Deploy Prometheus operator in monitoring namespace
  - [ ] Configure Prometheus server with HA setup
  - [ ] Set up persistent storage for metrics retention
  - [ ] Configure service discovery and scraping
- [ ] Configure Prometheus to scrape management cluster metrics (AC: 1)
  - [ ] Set up cluster-wide service monitoring
  - [ ] Configure ASO controller metrics collection
  - [ ] Configure Flux controller metrics collection
  - [ ] Set up Kubernetes API server metrics
  - [ ] Configure etcd cluster monitoring
- [ ] Install Grafana and create initial dashboards (AC: 2)
  - [ ] Deploy Grafana with persistent storage
  - [ ] Configure Grafana data sources
  - [ ] Create management cluster overview dashboard
  - [ ] Create ASO operational dashboard
  - [ ] Create Flux GitOps dashboard
  - [ ] Create security monitoring dashboard
- [ ] Setup AlertManager with notification channels (AC: 3)
  - [ ] Deploy AlertManager with HA configuration
  - [ ] Configure Slack notification channel
  - [ ] Configure email notification channel
  - [ ] Set up PagerDuty integration for critical alerts
  - [ ] Configure alert routing and grouping rules
- [ ] Configure Azure Monitor integration (AC: 4)
  - [ ] Enable Azure Monitor for containers
  - [ ] Set up Log Analytics workspace integration
  - [ ] Configure Azure Monitor metrics export
  - [ ] Set up Azure Alert Rules
  - [ ] Configure Azure Monitor dashboards
- [ ] Create custom metrics for ASO reconciliation (AC: 5)
  - [ ] Implement ASO reconciliation duration metrics
  - [ ] Create ASO resource provisioning success rate metrics
  - [ ] Set up cross-subscription access metrics
  - [ ] Create Flux synchronization performance metrics
  - [ ] Implement GitOps deployment success metrics

## Dev Notes

### Previous Story Dependencies
This story builds on all previous Epic 1 stories as it provides observability for the entire management cluster ecosystem.

### Monitoring Stack Architecture
**Observability Platform** [Source: architecture.md#observability-stack]:
```yaml
observability_stack:
  metrics:
    prometheus:
      version: "v2.47+"
      retention: "90d"
      storage: "azure_disk_premium"
      federation: "cross_cluster"

    azure_monitor:
      container_insights: true
      prometheus_metrics: true
      managed_grafana: true

  logging:
    fluent_bit:
      version: "v2.2+"
      outputs:
        - "azure_log_analytics"
        - "prometheus_metrics"

  visualization:
    grafana:
      version: "v10.2+"
      dashboards:
        - "kubernetes_cluster_monitoring"
        - "application_performance"
        - "security_monitoring"
        - "cost_optimization"
```

### Prometheus Configuration
**Prometheus Server Configuration**:
```yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: management-cluster
  namespace: monitoring
spec:
  replicas: 2
  retention: "90d"
  retentionSize: "50GB"
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: managed-premium
        resources:
          requests:
            storage: 100Gi
  serviceMonitorSelector:
    matchLabels:
      team: platform
  ruleSelector:
    matchLabels:
      role: alert-rules
  resources:
    requests:
      memory: "2Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  additionalScrapeConfigs:
    name: additional-scrape-configs
    key: prometheus-additional.yaml
```

**Service Monitor for ASO**:
```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: azure-service-operator
  namespace: monitoring
  labels:
    team: platform
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: azure-service-operator
  namespaceSelector:
    matchNames:
      - azure-service-operator-system
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### Grafana Dashboards
**Management Cluster Overview Dashboard**:
```json
{
  "dashboard": {
    "title": "Management Cluster Overview",
    "panels": [
      {
        "title": "Cluster Health",
        "targets": [
          {
            "expr": "up{job=\"kubernetes-nodes\"}",
            "legendFormat": "Node {{instance}}"
          }
        ]
      },
      {
        "title": "ASO Controller Status",
        "targets": [
          {
            "expr": "up{job=\"azure-service-operator-metrics\"}",
            "legendFormat": "ASO Controller"
          }
        ]
      },
      {
        "title": "Flux Reconciliation Status",
        "targets": [
          {
            "expr": "gotk_reconcile_condition{type=\"Ready\"}",
            "legendFormat": "{{kind}}/{{name}}"
          }
        ]
      }
    ]
  }
}
```

**ASO Operational Dashboard**:
```json
{
  "dashboard": {
    "title": "Azure Service Operator Operations",
    "panels": [
      {
        "title": "Resource Reconciliation Rate",
        "targets": [
          {
            "expr": "rate(controller_runtime_reconcile_total{controller=~\".*azure.*\"}[5m])",
            "legendFormat": "{{controller}}"
          }
        ]
      },
      {
        "title": "Azure API Rate Limiting",
        "targets": [
          {
            "expr": "azure_api_requests_total",
            "legendFormat": "{{method}} {{resource_type}}"
          }
        ]
      },
      {
        "title": "Cross-Subscription Operations",
        "targets": [
          {
            "expr": "aso_cross_subscription_operations_total",
            "legendFormat": "{{subscription}} {{operation}}"
          }
        ]
      }
    ]
  }
}
```

### AlertManager Configuration
**AlertManager Configuration**:
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-config
  namespace: monitoring
stringData:
  alertmanager.yml: |
    global:
      slack_api_url: 'https://hooks.slack.com/services/...'

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'platform-team'
      routes:
      - match:
          severity: critical
        receiver: 'pagerduty-critical'
      - match:
          severity: warning
        receiver: 'slack-warnings'

    receivers:
    - name: 'platform-team'
      slack_configs:
      - channel: '#platform-alerts'
        title: 'Management Cluster Alert'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

    - name: 'pagerduty-critical'
      pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
        description: 'Critical alert in management cluster'

    - name: 'slack-warnings'
      slack_configs:
      - channel: '#platform-warnings'
        title: 'Management Cluster Warning'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
```

### Custom Metrics Implementation
**ASO Custom Metrics**:
```yaml
# ServiceMonitor for custom ASO metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: aso-custom-metrics
spec:
  selector:
    matchLabels:
      app: aso-metrics-exporter
  endpoints:
  - port: metrics
    path: /custom-metrics
    interval: 60s

---
# Custom metrics ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: aso-metrics-config
data:
  metrics.yaml: |
    metrics:
      - name: aso_resource_provisioning_duration_seconds
        help: Time taken to provision Azure resources
        type: histogram
        labels: [resource_type, subscription, environment]

      - name: aso_reconciliation_success_rate
        help: Success rate of ASO resource reconciliation
        type: gauge
        labels: [controller, resource_type]

      - name: aso_cross_subscription_operations_total
        help: Total cross-subscription operations
        type: counter
        labels: [subscription, operation, status]
```

### Azure Monitor Integration
**Container Insights Configuration**:
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: container-azm-ms-agentconfig
  namespace: kube-system
data:
  schema-version: v1
  config-version: ver1
  log-data-collection-settings: |
    [log_collection_settings]
      [log_collection_settings.stdout]
        enabled = true
        exclude_namespaces = ["kube-system"]
      [log_collection_settings.stderr]
        enabled = true
        exclude_namespaces = ["kube-system"]
  prometheus-data-collection-settings: |
    [prometheus_data_collection_settings.cluster]
      interval = "1m"
      monitor_kubernetes_pods = true
    [prometheus_data_collection_settings.node]
      interval = "1m"
```

### Critical Alert Rules
**Management Cluster Alert Rules**:
```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: management-cluster-alerts
  namespace: monitoring
spec:
  groups:
  - name: management-cluster
    rules:
    - alert: ManagementClusterDown
      expr: up{job="kubernetes-apiservers"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Management cluster API server is down"
        description: "Management cluster API server has been down for more than 5 minutes"

    - alert: ASOControllerDown
      expr: up{job="azure-service-operator-metrics"} == 0
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "ASO controller is down"
        description: "Azure Service Operator controller has been down for more than 2 minutes"

    - alert: FluxReconciliationFailing
      expr: gotk_reconcile_condition{type="Ready",status="False"} == 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Flux reconciliation failing"
        description: "Flux {{ $labels.kind }}/{{ $labels.name }} has been failing reconciliation for 5 minutes"

    - alert: HighMemoryUsage
      expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage on node {{ $labels.instance }}"
        description: "Node memory usage is above 80%"
```

### File Locations
**Monitoring Configuration Structure** [Source: folder-structure.md]:
```
eng/azureserviceoperator/managementcluster/monitoring/
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ prometheus.yaml
â”‚   â”œâ”€â”€ service-monitors.yaml
â”‚   â””â”€â”€ recording-rules.yaml
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”œâ”€â”€ cluster-overview.json
â”‚   â”‚   â”œâ”€â”€ aso-operations.json
â”‚   â”‚   â””â”€â”€ flux-gitops.json
â”‚   â””â”€â”€ grafana-config.yaml
â”œâ”€â”€ alertmanager/
â”‚   â”œâ”€â”€ alertmanager-config.yaml
â”‚   â””â”€â”€ alert-rules.yaml
â””â”€â”€ azure-monitor/
    â”œâ”€â”€ container-insights.yaml
    â””â”€â”€ log-analytics.yaml
```

## Testing

### Monitoring Functionality Testing
- Metrics collection accuracy and completeness
- Dashboard functionality and data visualization
- Alert rule threshold validation and notification delivery
- Azure Monitor integration and data export

### Performance Testing
- Monitoring system resource utilization
- Metrics ingestion and query performance
- Dashboard loading times and responsiveness
- Alert processing latency and delivery times

### Reliability Testing
- Monitoring system high availability validation
- Data persistence and recovery testing
- Network connectivity failure handling
- Monitoring system upgrade and maintenance procedures

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-19 | 1.0 | Initial story creation | Scrum Master |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

## QA Results
*This section will be populated by the QA agent after story completion*